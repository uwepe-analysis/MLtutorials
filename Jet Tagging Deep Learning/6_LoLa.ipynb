{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoLa\n",
    "\n",
    "Written by Vince Ling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper link:https://arxiv.org/pdf/1707.08966.pdf. Read the paper before going forward. It is important that you understand the math and the structure of lola and cola layers before the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we are doing two-classifier job in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Understanding data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset link: https://zenodo.org/record/2603256#.X7VrlGhKiUm There are 3 files, contains in total 1.2M training events, 400k validation events and 400k test events. We will work with training dataset, which is the 1GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "input_filename = \"data/train.h5\"\n",
    "store = pd.read_hdf(input_filename, 'table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are 1211000 rows x 806 columns. 1211000 means there are 1.2 million jets, 806 columns means we have `E0, PX0, PY0, PZ0` to `E199, PX199, PY199, PZ199`(800) with `truthE, truthPX, truthPY, truthPZ, ttv, is_signal_new`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means for each jet, we are at most 200 momenta, 1 truth momenta and we can check what kind of dataset by `ttv`, and wheather it is a signal(top) or a background(qcd) by `is_signal_new`(1 for signal 0 for background)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the input for LOLA is four momenta array, we need to process them to a four momenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we will split the train dataset from signal and background.\n",
    "signal = store[store['is_signal_new']==1]\n",
    "background = store[store['is_signal_new']==0]\n",
    "print(signal.shape)\n",
    "print(background.shape)\n",
    "#we can see there are 600k of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadmomenta(dataset, nConstituents=40):\n",
    "    #this function takes a input of top tagging dataset and return a four momenta array\n",
    "    momenta = dataset.values[:, :nConstituents*4]\n",
    "    momenta = np.reshape(momenta, (len(momenta), nConstituents, 4))\n",
    "    momenta = np.transpose(momenta, [0, 2, 1])\n",
    "    labels = dataset.values[:, -1]\n",
    "    indices = np.random.permutation(len(labels))\n",
    "    return momenta[indices], labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_momenta, signal_labels = loadmomenta(signal)\n",
    "background_momenta, background_labels = loadmomenta(background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "momenta = np.append(background_momenta, signal_momenta, axis=0)\n",
    "labels = keras.utils.to_categorical(np.append(background_labels, signal_labels), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the test and validation dataset for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cola class and Lola class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'lib')\n",
    "import classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now contruct the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = classes.LoLaClassifier(nConstituents=40, nAdded=10).model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "            optimizer=keras.optimizers.Adam(lr=0.0001), \n",
    "            loss='binary_crossentropy', \n",
    "            metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(momenta, labels,\n",
    "        batch_size=1024,\n",
    "        validation_split=0.25,\n",
    "        epochs=10, \n",
    "        shuffle=True, \n",
    "        callbacks=None,\n",
    "        use_multiprocessing=True, \n",
    "        workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def learningCurveLoss(history):\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'], linewidth=1)\n",
    "    plt.plot(history.history['val_loss'], linewidth=1)\n",
    "    plt.title('Model Loss over Epochs')\n",
    "    plt.legend(['training sample loss','validation sample loss'])\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningCurveLoss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is your time to finish the ROC curve and other evaluations for Lola network with two classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, we uesed the train.py for validation, training and testing. It is up to you that if you want to load all the dataset from the website to run this code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a two-taggers job. One of the most important goals in our research team is to convert these kind of problems into a 5-classifiers job using our data, and compare their performances. Since you have finished couple of 5-tagger problems, now it is time for you to modify these codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Convert the training dataset with this shape: (98769, 4, 40),lables shape: (98769, 5).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
